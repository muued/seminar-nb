\documentclass{beamer}
\usetheme{STCE}
\usepackage{beamerfoils}
\uselanguage{German}
\languagepath{German}

\usepackage{epstopdf}

\usepackage{ucs} % Unicode - dependency of utf8x inputenc
\usepackage[utf8x]{inputenc} % "utf8x" uses "ucs"-package, better than "UTF8"
\usepackage[T1]{fontenc}
\usepackage{lmodern}

\usepackage[german]{babel}
\usepackage{amsmath, amssymb, amsxtra, amsthm, pxfonts, stmaryrd}
\usepackage{epsfig,psfrag, epstopdf}
\usepackage{listings}

\usepackage{tikz}

\usepackage{nicefrac}


\beamertemplatenavigationsymbolsempty % turn off navigation bar

\lstloadlanguages{[ISO]C++, R}
\lstset{basicstyle=\small, numbers=left, numberstyle=\footnotesize, tabsize=2,  stepnumber=1, numbersep=5pt, breaklines=true, escapeinside={/*@}{@*/}}

\setbeamertemplate{footline}[frame number]

\MyLogo{
\centering
\includegraphics[width=0.12\textwidth]{./figures/logo.eps}
}

\AtBeginSection[]
{
	\begin{frame}
		\tableofcontents[sectionstyle=show/shaded, subsectionstyle=show/show/shaded, subsubsectionstyle=show/show/hide]
	\end{frame} 
}

\begin{document}
\title{\centering
\includegraphics[width=0.25\textwidth]{./figures/logo.eps} \\ Numerische Bibliotheken}

\subtitle{Der $\chi^2$ und Kolmogorow-Smirnow Test}
\author{Christian Janßen (302530) \\ Fabian Ohler (280424) }
\date{6. August 2013}
\institute{
LuFG Informatik 12: Software and Tools for Computational Engineering}
\frame[plain]{\titlepage}

%%% Inhalt
\begin{frame}{Inhalt}
	\tableofcontents
\end{frame}

%%%Einführung
\section{Einführung}
\begin{frame}{\insertsection}
		\begin{block}{Statistik}
			\begin{itemize}
			\item ist das Sammeln, Auswerten und Beurteilen von Daten
			\item dient als Bindeglied zwischen Daten und Hypothesen
			\end{itemize}
 		\end{block}
		\begin{block}{Numerische Bibliotheken}
			\begin{itemize}
			\item stellen mathematische Algorithmen zur Verfügung wodurch eine eigene Implementation entfällt
			\item sind in diesem Vortrag NAG C und die Sprache R
			\end{itemize}
 		\end{block}
\end{frame}

%%%Statistische Grundlagen
\section{Statistische Grundlagen}

\begin{frame}{\insertsection}
\begin{definition}
	\begin{description}[Punkt im Ergebnisraum]
	\item[Experiment] verschiedene mögliche Ausgänge
	\item[Ergebnisraum] Menge aller möglichen Ausgänge
	\item[Punkt im Ergebnisraum] ein konkreter Ausgang
	\item[Ereignis] Menge von Punkten im Ergebnisraum
	\item[P: Ergebnisraum $\rightarrow\mathbb{R}$] Wahrscheinlichkeitsfunktion
	\item[P(A)] Wahrscheinlichkeit für Ereignis A
	\end{description}
\end{definition}
\end{frame}

\begin{frame}{\insertsection}
\begin{example}[Münzwurf]
	\begin{description}[Punkt im Ergebnisraum]
	\item[Experiment] wirf eine (faire) Münze zwei Mal
	\item[Ergebnisraum] $E \coloneqq \{ZZ,ZK,KZ,KK\}$
	\item[Punkt im Ergebnisraum] z.\,B.~$KK \in E$
	\item[Ereignis] z.\,B.~mind.~1x Kopf: $\{ZK, KZ, KK\} \subseteq E$
	\item[P(A)] = $0.25 ~\forall A\in E$
	\item[P(mind.~1x Kopf)] = 0.75
	\end{description}
\end{example}
\end{frame}

\begin{frame}{\insertsection}
\begin{definition}
	\begin{description}[kumulierte Verteilungsfunktion]
	\item[Zufallsvariable X] \emph{sortiert} Punkte im Ergebnisraum
	\item[Dichtefunktion] $f(x) = P(X=x)$
	\item[kumulative Verteilungsfunktion] $F(x) = P(X \leq x)$
	\item[Quantil] $x_p: ~ P(X\leq x_p)\geq p$ und $P(X\geq x_p)\geq 1-p$
	\item[Median] $x_{0.5}$
	\item[Erwartungswert] $\mu = E(X) = \int x\cdot f(x) \text{d}x$
	\item[Varianz] $\sigma^2 = E[(X-\mu)^2]$
	\item[Standardabweichung] $\sigma = \sqrt{\sigma^2}$
	\end{description}
\end{definition}
\end{frame}

\begin{frame}{\insertsection}
\begin{block}{Normalverteilung $\mathcal{N}(\mu,\sigma^2)$}
	$\mu$ Erwartungswert, $\sigma^2$ Varianz \\
	kumulative Verteilungsfunktion:
	\begin{equation*}
	F(x) = \Phi\left(\frac{x - \mu}{\sigma}\right) = \frac{1}{\sqrt{2\pi\sigma}} \int_{-\infty}^{x}e^{-\frac{1}{2}[(y-\mu)/\sigma]^2}\textrm{d}y
	\end{equation*}
\end{block}
\end{frame}

\begin{frame}{\insertsection}
	\begin{figure}[htbp]
		\centering
		\includegraphics[height=0.99\textheight]{figures/standardnorm_empty}
	\end{figure}
\end{frame}
%quantil
\begin{frame}{\insertsection}
	\begin{figure}[htbp]
		\centering
		\includegraphics[height=0.99\textheight]{figures/standardnorm_quantil}
	\end{figure}
\end{frame}
%F
\begin{frame}{\insertsection}
	\begin{figure}[htbp]
		\centering
		\includegraphics[height=0.99\textheight]{figures/standardnorm}
	\end{figure}
\end{frame}

\begin{frame}{\insertsection}
\begin{block}{Gleichverteilung $\mathcal{U}(a,b)$}
	$a$ Minimum, $b$ Maximum \\
	kumulative Verteilungsfunktion:
	\begin{equation*}
	F(x) = \left\{\begin{tabular}{ll}
	0 & for $x<a$ \\
	$\frac{x-b}{b-a}$ & for $a\leq x<b$ \\
	1 & for $x\geq b$ \\
	\end{tabular}\right.
	\end{equation*}
\end{block}
\end{frame}

\begin{frame}{\insertsection}
\begin{block}{Binomialverteilung $B(n,p)$}
	$n$ Anzahl der Erfolge, $p$ Wahrscheinlichkeit des Erfolgs bei booleschem Ergebnis \\
	kumulative Verteilungsfunktion:
	\begin{equation*}
	F(x) = \sum_{i\leq x} \genfrac(){0pt}{}{n}{i} p^{i}q^{n-i}
	\end{equation*}
\end{block}
\end{frame}


\begin{frame}{\insertsection}
\begin{block}{Chi-Quadrat-Verteilung $\chi^2(k)$}
	$k$ Anzahl der Freiheitsgrade \\
	kumulative Verteilungsfunktion:
	\begin{equation*}
	F(x) = \left\{\begin{tabular}{ll}
	$\int_{0}^{x} \frac{y^{(k/2)-1}e^{(y/2)}}{2^{k/2}\Gamma(k/2)}\textrm{d}y$ & if $x>0$ \\
	0 & if $x\leq 0$
	\end{tabular}\right.
	\end{equation*}
\end{block}
\begin{example}
	$X_1, \ldots X_k$ unabhängig \& gleich normalverteilt \\
	$Y = \sum_{i=1}^{k}X_i^2$ ist $\chi^2$-verteilt mit $k$ Freiheitsgraden
\end{example}
\end{frame}

\begin{frame}{\insertsection}
\begin{definition}
	\begin{description}[Zufallsstichprobe]
	\item[Grundgesamtheit] alle relevanten Elemente
	\item[Stichprobe] Teilmenge der Grundgesamtheit
	\item[Zufallsstichprobe] Stichprobe, bei der jedes Element gleich wahrscheinlich war
	\item[] 
	\end{description}
\end{definition}
\begin{definition}[empirische Verteilungsfunktion]
	Zufallsstichprobe, Größe $n$
	\begin{equation*}
	S(x) = \frac{1}{n}(\text{\#Stichprobenelemente}\leq x)
	\end{equation*}
\end{definition}
\end{frame}

\begin{frame}{\insertsection}
\begin{definition}[Qualität eines Schätzers]
	\begin{description}[Zuverlässigkeit]
	\item[Präzision] Nähe zum echten Wert
	\item[Zuverlässigkeit] Wahrscheinlichkeit, korrekt zu sein
	\end{description}
\end{definition}
\begin{example}[Punktschätzer, hohe Präzision, geringe Zuverlässigkeit]
	\begin{description}[Beispiele]
	\item[Beispiele] Mittelwert, Stichprobenvarianz Punktschätzer für Erwartungswert, Varianz
	\end{description}
\end{example}
\begin{example}[Konfidenzintervall, geringe Präzision, hohe Zuverlässigkeit]
	\begin{description}[Beispiele]
	\item[Beispiel] \glqq Wir sind zu 90\% sicher, dass weniger als 1\% unserer Produkte fehlerhaft sind\grqq.
	\end{description}
\end{example}
\end{frame}

\begin{frame}{\insertsection}
\begin{block}{statistisches Schließen}
	Stichprobe $\Rightarrow$ Grundgesamtheit (Induktion)
	\\
	Gegenteil: Deduktion
\end{block}
\begin{block}{Hypothesen-Tests}
	Methode der Entscheidungsfindung:\\
	\emph{Kann allg.~Aussage über Grundgesamtheit wegen Stichprobe angenommen werden?}
\end{block}
\begin{definition}[Hypothese lt.~Wiktionary]
	unbewiesene (wissenschaftliche) Annahme, die noch eines Beweises bedarf
\end{definition}
\end{frame}

\begin{frame}{\insertsection}
\begin{definition}
	\begin{description}[Alternativhypothese]
	\item[Statistischer Test] prüft Hypothese gegen Stichprobe
	\item[Nullhypothese] zu prüfende Hypothese ($H_0$)
	\item[Alternativhypothese] Komplement der Nullhypothese ($H_1$)
	\end{description}
\end{definition}
\begin{block}{Mögliche Test-Ergebnisse}
	\begin{itemize}
	\item $H_0$ wird verworfen
	\item $H_0$ wird nicht verworfen (keine Aussage)
	\end{itemize}
\end{block}
\begin{block}{Vorgehensweise}
	\begin{description}[$H$ widerlegen]
	\item[$H$ beweisen] wähle $H$ als Alternativhypothese
	\item[$H$ widerlegen] wähle $H$ als Nullhypothese
	\end{description}
\end{block}
\end{frame}

\begin{frame}{\insertsection}
\begin{definition}
	\begin{description}[Signifikanzniveau]
	\item[Kritische Region] Teilmenge der Stichprobe, die zu Ablehnung der Nullhypothese führt
	\item[Fehler 1. Art] korrekte Nullhypothese wird verworfen
	\item[Fehler 2. Art] falsche Nullhypothese wird nicht verworfen
	\item[Signifikanzniveau] Wahrscheinlichkeit für Fehler 1. Art ($\alpha$)
	\item[p-Wert] Wahrscheinlichkeit für eine derart \emph{extreme} Stichprobe unter der Nullhypothese
	\end{description}
\end{definition}
\end{frame}

%%%Kolmogorow-Smirnow Test
\section{Kolmogorow-Smirnow Test}
\begin{frame}{\insertsection}
\begin{block}{Kolmogorow-Smirnow Test hat zwei Anwendungen}
	\begin{itemize}
		\item[1.] Pr\"uft Mengen $X$ und $ Y$ auf gleiche Wahrscheinlichkeitsverteilung \\
		\item[2.] Pr\"uft Menge $X$ auf spezifizierte Wahrscheinlichkeitsverteilung
			\[S(x)=F(x)\]
	%		\begin{center}$\rightarrow$ Anpassungsg\"utetest\end{center}
	\end{itemize}
\end{block}
\end{frame}

	%%%Mathematischer Hintergrund
\subsection{Mathematischer Hintergrund}

\begin{frame}{\insertsubsection}
\begin{block}{Anwendung des Anpassungsgütetests}
	\begin{itemize}
		\item[1.] Menge $X$ aufsteigend sortieren, $x_1\le ...\le x_n$
		\item[2.]<2-> Bilden der empirischen Verteilungsfunktion $S(x)$	
		\only<2>{ $$S(x)=\frac{1}{n}\sum^{n}_{i=1}I_{x_i\le x}$$}
		\item[3.]<3-> Spezifizieren der angenommenen Verteilungsfunktion $F(x)$
		\item[4.]<3-> Aufstellen der Nullhypothese $H_0$ und der Alternativhypothese $H_1$
		\only<3>{$$H_0:S(x)=F(x)$$ $$H_1:S(x)\neq F(x)$$}
		\item[5.]<4-> Ermitteln der Teststatistik $D_n$
		\only<4>{ $$D_n=\max(d_0,d_1)$$ $$ d_0=\max_x|S(x)-F(x)|,$$ $$d_1=\max_x|S(x_{i-1})-F(x_i)|$$ }
		\item[6.]<5->Wenn $D_n>D_\alpha$ wird die Nullhypothese verworfen
	\end{itemize}
\end{block}
\end{frame}

	%%%Beispiel

\begin{frame}{\insertsubsection}
\begin{example}[KS-Test Anwendung]
	\begin{itemize}
		\item Beobachtungen:
			\begin{table}[h]
			\center
			\begin{tabular}{c|c|c|c|c|c|c|c|c|c}
			$x_1$	&$x_2$	&$x_3$	&$x_4$	&$x_5$	&$x_6$	&$x_7$	&$x_8$	&$x_9$	&$x_{10}$\\
			\hline
			1.0	&1.1	&1.2	&1.6	&1.7	&2.1	&2.1	&2.4	&2.4	&2.5	\\
			\end{tabular}
			\begin{tabular}{c|c|c|c|c|c|c|c|c|c}
			$x_{11}$	&$x_{12}$	&$x_{13}$	&$x_{14}$	&$x_{15}$	&$x_{16}$	&$x_{17}$	&$x_{18}$	&$x_{19}$	&$x_{20}$\\
			\hline
			2.6	&2.6	&2.6	&2.7	&2.8	&3.0	&3.3	&3.5	&3.8	&4.2\\
			\end{tabular}
			\end{table}
		\item Hypothesen: $$H_{Franz}:S(x)=\Phi(x|3.5;1)$$ $$H_{Paul}:S(x)=\Phi(x|3;0.7)$$
	\end{itemize}
\end{example}
\end{frame}

\begin{frame}{\insertsubsection}
\begin{example}[KS-Test Anwendung]
	\begin{itemize}
		\item Werte der Verteilungsfunktionen
			\begin{table}[ht]
			\center
			\begin{tabular}{c|c|c|c|c}
			$i$ 	& $x_i$ 	& $S(x_i)$ 	& $\Phi (x_i|3;0,7)$ 	& $\Phi (x_i|3,5;1)$ 	\\
			\hline
			1	&	1	&	0.05	&	0.002137	&	0.006210	\\
			12	&	2.6	&	0.65	&	0.283855	&	0.184060	\\
			15	&	2.8	&	0.75	&	0.387548	&	0.241964	\\
			20	&	4.2	&	1	&	0.956762	&	0.758036	\\
			\end{tabular}
			\end{table}
		\item Werte der Teststatistik
			\begin{table}[ht]
			\center
			\begin{tabular}{c|c|c|c|c}
			$i$ 	& $d_{0,Paul}(x_i)$ 	& $d_{1,Paul}(x_i)$ 	& $d_{0,Franz}(x_i)$ 	& $d_{1,Franz}(x_i)$ 	\\
			\hline
			1	&	0.047863	&	0.002137	&	0.043790	&	0.006210	\\
			12	&	0.366145	&	0.366145	&	0.465940	&	0.465940	\\
			15	&	0.362452	&	0.312452	&	0.508036	&	0.458036	\\
			20	&	0.043238	&	0.006762	&	0.241964	&	0.191964	\\
			\end{tabular}
			\end{table}
	\end{itemize}
\end{example}
\end{frame}

\begin{frame}{\insertsubsection}
\begin{example}[KS-Test Anwendung]
Auswertung der Teststatistiken:
	\begin{itemize}
		\item $D_{n,Franz}=0.508036$ und $D_{n,Paul}=0.366145$
		\item $D_\alpha=0.294$
	\end{itemize}
Somit sind beide Hypothesen verworfen.
\end{example}
\end{frame}

	%%%NAG C
\subsection{Implementierung in NAG C}
\begin{frame}[fragile]{\insertsubsection}
\begin{block}{\lstinline[language=C++]$nag_1_sample_ks_test$ oder \lstinline[language=C++]$g08cbc$}
	\lstinline[language=C++]$g08cbc(n, x[], dist, par[], estima, dtype, *d, *z, *p, *fail)$
\end{block}
%In NAG C: \lstinline[language=C++]$g08cbc$ oder \lstinline[language=C++]$nag_1_sample_ks_test$ mit folgenden Parametern:\\
%\begin{center}\lstinline[language=C++]$g08cbc(n, x[], dist, par[], estima, dtype, *d, *z, *p, *fail)$\end{center}
\begin{block}{Die Eingabeparameter}
	\begin{description}
		\item[n] -- Integer der die Anzahl der Beobachtungen speichert
		\item[x{[n]}] -- Double Array mit den Beobachtungen $x_1...x_n$
		\item[dist] -- Nag\_Distribution spezifiziert $F(x)$
		\item[par{[2]}] -- Enthält optional weitere Parameter für $dist$
		\item[estima] -- Nag\_ParaSupplied falls $par$ gegeben ist oder Nag\_ParaEstimated wenn die Parameter von NAG bestimmt werden sollen
		\item[dtype] -- definiert Nag\_TestStatistics
	\end{description}
\end{block}
\end{frame}

\begin{frame}[fragile]{\insertsubsection}
\begin{example}[dtype]
$dtype$ muss einer der drei folgenden Werte zugewiesen werden:
	\begin{itemize}
		\item Nag\_TestStatisticsDAbs
		\item Nag\_TestStatisticsDPos
		\item Nag\_TestStatisticsDNeg
	\end{itemize}
	\center \includegraphics[width=.8\textwidth]{figures/diagramKSd-d+.png}
\end{example}
\end{frame}

\begin{frame}[fragile]{\insertsubsection}
\begin{block}{\lstinline[language=C++]$nag_1_sample_ks_test$ oder \lstinline[language=C++]$g08cbc$}
	\lstinline[language=C++]$g08cbc(n, x[], dist, par[], estima, dtype, *d, *z, *p, *fail)$
\end{block}
\begin{block}{Die Ausgabeparameter}
	\begin{description}
		\item[*d] -- Double mit dem Wert der Teststatistik
		\item[*z] -- Double mit dem $z$ Wert
		\item[*p] -- Double mit $p$ Wert
		\item[*fail] -- NagError mit etwaigen Fehlerbeschreibungen
	\end{description}
\end{block}
\end{frame}

	%%%R
\subsection{Alternative Bibliotheken}
\begin{frame}{\insertsubsection}

\begin{block}{R als alternative Bibliothek}
	\lstinline[language=R] $ks.test(x, y, ..., alternative)$
\end{block}

\begin{block}{Die Eingabeparameter}
\begin{description}
	\item[x] -- Numerischer Vektor mit  allen Beobachtungen
	\item[y] -- String welche die Nullverteilung beschreibt
	\item[...]-- Strings mit Parametern für $y$
	\item[alternative]-- definiert welche Teststatistik berechnet wird
\end{description}
\end{block}

\end{frame}

\begin{frame}{\insertsubsection}

\begin{block}{R als alternative Bibliothek}
	\lstinline[language=R] $ks.test(x, y, ..., alternative)$
\end{block}

\begin{block}{Die Rückgabeparameter}
\begin{description}
	\item[statistic] -- Teststatistik welche in $alternative$ festgelegt wurde
	\item[p.value] -- p Wert
	\item[alternative] -- gewählter Wert für $alternative$
	\item[method] -- genutzter Test
	\item[data.name] -- Namen der Daten
\end{description}
\end{block}

\end{frame}

%%%$\chi^2$ Test
\section{$\chi^2$ Test}
\begin{frame}{\insertsection}
\begin{block}{$\chi^2$ Tests}
	Familie von Tests mit $\chi^2$-verteilter Teststatistik.
	\\
	Hier betrachtet: Pearson's $\chi^2$ Test (Anpassungsgütetest)
\end{block}
\begin{block}{Anwendungsfälle}
	\begin{description}[Alternativhypothese]
	\item[Nullhypothese] Die Stichprobe genügt spezifizierter Verteilung
	\item[Alternativhypothese] Die Stichprobe genügt irgend einer anderen als der spezifizierten Verteilung
	\item[Verwerfen von $H_0$] falls Stichprobe \emph{dagegen spricht}
	\end{description}
\end{block}
\end{frame}

\subsection{Mathematischer Hintergrund}

\begin{frame}{\insertsubsection}
\begin{block}{Eingabe}
	\begin{description}[Signifikanzniveau]
	\item[Zufallsstichprobe] von $n$ unabhängigen Ereignissen $x_1, \ldots, x_n$
	\item[Klassenanzahl] Ereignisse sollen gruppiert werden in $k$ Klassen
	\item[Klassengrenzen] $k-1$ Werte ($c_i$), die die Stichprobe partitionieren
	\item[Signifikanzniveau] $\alpha$
	\end{description}
\end{block}
\begin{block}{Vorbereitung: Berechnung der beobachteten Klassen-Häufigkeiten}
	$O_i = \left|\{ x_a ; c_{i-1} < x_a \leq c_i \}\right| ~ \forall 1 \leq i \leq k$
	\\
	$c_0 = -\infty, ~ c_k = \infty$
\end{block}
\end{frame}

\begin{frame}{\insertsubsection}
\begin{definition}
	\begin{description}[$E_i$]
	\item[$F$] Verteilungsfunktion der Nullhypothese
	\item[$d$] Anzahl Parameter der Verteilungsfunktion, die aus Stichprobe abgelesen wurden
	\item[$E_i$] erwartete Anzahl an Werten in Klasse $i$ unter falls $H_0$
	\end{description}
\end{definition}
\begin{block}{Vorbereitung: Berechnung der erwarteten Klassen-Häufigkeiten}
	$E_i = n \cdot P(c_{i-1} < X \leq c_i) ~ \forall 1 \leq i \leq k$
	\\
	$c_0 = -\infty, ~ c_k = \infty$
\end{block}
\end{frame}

\begin{frame}{\insertsubsection}
\begin{definition}[Teststatistik]
	\begin{equation*}
		X^2 = \sum_{i=1}^{k}\frac{(O_i - E_i)^2}{E_i}
	\end{equation*}
\end{definition}
\begin{block}{Entscheidung}
	Verwirf $H_0$, falls $X^2 > x_{1-\alpha}$ \\[1ex]
	$x_{1-\alpha}$ ist $(1-\alpha)$-Quantil der $\chi^2$-Verteilung mit $k-1-d$ Freiheitsgraden
\end{block}
\end{frame}

\begin{frame}{\insertsection}
\begin{example}[Beobachtungen]
	\begin{table}[htb]
	\center
	\begin{tabular}{cccccccccc}
	$x_1$	&$x_2$	&$x_3$	&$x_4$	&$x_5$	&$x_6$	&$x_7$	&$x_8$	&$x_9$	&$x_{10}$\\
	\hline
	14.6	&15.4	&15.5	&16.2	&17.3	&18.0	&18.7	&19.5	&19.7	&19.9	\\
	\end{tabular}
	\begin{tabular}{cccccccccc}
	$x_{11}$	&$x_{12}$	&$x_{13}$	&$x_{14}$	&$x_{15}$	&$x_{16}$	&$x_{17}$	&$x_{18}$	&$x_{19}$	&$x_{20}$\\
	\hline
	20.1	&21.1	&21.7	&22.6	&23.1	&23.2	&24.1	&24.7	&24.8	&25.0	\\
	\end{tabular}
	\end{table}
\end{example}
\begin{example}[Hypothesen]
	\begin{align*}
		H_{\text{Franz}} &: S(x) = \Phi(x\mid 20.26, 11.297)
		\\
		H_{\text{Paul}} &: S(x) = \Phi(x\mid 20, 11)
	\end{align*}
\end{example}
\end{frame}

\begin{frame}{\insertsection}
\begin{example}[Bilden der Klassen]
	Setze $k=4$, nutze $ x_p = \mu + \sigma w_p $
	\begin{align*}
		x_{0.25, \text{Franz}} &= 20.26 + \sqrt{11.297}(-0.6745) \approx 17.993 \\
		x_{0.5, \text{Franz}} &= 20.26 \\
		x_{0.75, \text{Franz}} &= 20.26 + \sqrt{11.297}(+0.6745) \approx 22.527
		\\[1ex]
		x_{0.25, \text{Paul}} &= 20 + \sqrt{11}(-0.6745) \approx 17.763\\
		x_{0.5, \text{Paul}} &= 20 \\
		x_{0.75, \text{Paul}} &= 20 + \sqrt{11}(+0.6745) \approx 22.237
	\end{align*}
\end{example}
\end{frame}

\begin{frame}{\insertsection}
\begin{example}[Häufigkeitstabelle von Franz]
	\begin{table}[htb]
	\center
	\begin{tabular}{l|cccc}
		& $(-\infty, 17.993]$ & $(17.993, 20.26]$ & $(20.26, 22.527]$ & $(22.527,\infty)$ \\
		\hline
		E & 5 & 5 & 5 & 5 \\
		O & 5 & 6 & 2 & 7 \\
	\end{tabular}
	\end{table}
\end{example}
\begin{example}[Häufigkeitstabelle von Paul]
	\begin{table}[htb]
	\center
	\begin{tabular}{l|cccc}
	& $(-\infty, 17.763]$ & $(17.763, 20]$ & $(20, 22.237]$ & $(22.393,\infty)$ \\
	\hline
	E & 5 & 5 & 5 & 5 \\
	O & 5 & 5 & 3 & 7 \\
	\end{tabular}
	\end{table}
\end{example}
\end{frame}

\begin{frame}{\insertsection}
\begin{example}[Berechnung der Teststatistik]
	\begin{align*}
		X^2_{\text{Franz}} &= \frac{(5-5)^2}{5} + \frac{(6-5)^2}{5} + \frac{(2-5)^2}{5} + \frac{(7-5)^2}{5} = 2.8
		\\[1ex]
		X^2_{\text{Paul}} &= \frac{(5-5)^2}{5} + \frac{(5-5)^2}{5} + \frac{(3-5)^2}{5} + \frac{(7-5)^2}{5} = 1.6
	\end{align*}
\end{example}
\begin{example}[Entscheidung]
	$\alpha = 0.1$
	\begin{align*}
	d_\text{Paul} = 4-1-0 = 3 &\Rightarrow X^2_{\text{Paul}} = 1.6 \overset{!}{\leq} 6.261 = \chi^2_{0.9, 3} ~\checkmark
	\\
	d_\text{Franz} = 4-1-2 = 1 &\Rightarrow X^2_{\text{Franz}} = 2.8 \overset{!}{\leq} 2.706 = \chi^2_{0.9, 1} ~\lightning
	\end{align*}
\end{example}
\end{frame}

\subsection{Implementierung in NAG C}

\begin{frame}{\insertsubsection}
\begin{block}{nag\_chi\_sq\_goodness\_of\_fit\_test oder g08cgc}
	\lstinline[language=C++]!g08cgc(nclass, ifreq[], cint[], dist, par[], npest, prob[], *chisq, *p, *ndf, eval[], chisqi[], *fail)!
\end{block}
\begin{definition}[Eingabeparameter]
	\begin{description}[cint{[k-1]}]
	\item[nclass] Anzahl der Klassen
	\item[ifreq{[k]}] beobachtete Häufigkeiten
	\item[cint{[k-1]}] Grenzwerte der Klassen
	\item[dist] Verteilung (enum)
	\item[par{[2]}] Parameter von \emph{dist}
	\item[npest] Anzahl der aus der Stichprobe abgeleiteten Parameter d
	\item[prob{[k]}] Wahrscheinlichkeit, dass $X$ in der Klasse liegt (zum Definieren einer Verteilungsfunktion)
	\end{description}
\end{definition}
\end{frame}

\begin{frame}{\insertsubsection}
\begin{block}{Verteilungs-Enum}
	\begin{table}[htbp]
	\center
	\begin{tabular}{lll}
	NAG C Name & Verteilung & Parameter-Verwendung \\
	\hline
	Nag\_Normal & $\mathcal{N}(\mu,\sigma^2)$ & $\mu=\text{par}[0],~\sigma^2=\text{par}[1]$  \\
	Nag\_Uniform & $\mathcal{U}(a,b)$ & $a=\text{par}[0],~b=\text{par}[1]$ \\
	Nag\_Exponential & $\mathcal{E}\operatorname{xp}(\lambda)$ & $\lambda=\text{par}[0]$ \\
	Nag\_ChiSquare & $\chi^2(k)$ & $k=\text{par}[0]$ \\
	Nag\_Gamma & $\Gamma(\alpha,\beta)$ & $\alpha=\text{par}[0],~\beta=\text{par}[1]$
	\end{tabular}
	\end{table}
\end{block}
\end{frame}

\begin{frame}{\insertsubsection}
\begin{definition}[Ausgabeparameter]
	\begin{description}
	\item[*chisq] Teststatistik $X^2$
	\item[*p] p-Wert
	\item[*ndf] Anzahl der Freiheitsgrade für die Quantil-Bestimmung
	\item[eval{[k]}] erwartete Häufigkeiten der Klassen
	\item[chisqi{[k]}] Summanden der Teststatistik
	\item[*fail] NagError mit etwaiger Fehlerbeschreibung
	\end{description}
\end{definition}
\begin{block}{nag\_frequency\_table oder g01aec}
	nützlich zur Bestimmung der Häufigkeitstabellen
\end{block}
\end{frame}

\subsection{Alternative Bibliotheken}
\begin{frame}
\frametitle{$\chi^2$ Test}
\end{frame}

%%%Live Demo
\section{Live Demo}

\begin{frame}{\insertsection}
\center
\Huge Live Demo
\end{frame}

%%%Zusammenfassung
\section{Vergleich}

\begin{frame}{\insertsection}

\begin{columns}
\begin{column}{.48\textwidth}
\begin{block}{R}
	\begin{itemize}
		\item frei verfügbar
		\item leicht handhabbar
	\end{itemize}
\end{block}
\vspace{1cm}

\begin{block}{NAG C}
	\begin{itemize}
		\item kostenpflichtig
		\item komplex
		\item Support
	\end{itemize}
\end{block}
\end{column}

\hfill
\begin{column}{.48\textwidth}
\begin{block}{KS-Test}
	\begin{itemize}
		\item erstellen der empirischen Verteilungsfunktion
		\item benötigt weniger Beobachtungen als $\chi^2$
	\end{itemize}
\end{block}
%\vspace{.5cm}
\begin{block}{$\chi^2$-Test}
	\begin{itemize}		
		\item erstellen von Klassen
		\item bestimmen der Klassengröße
	\end{itemize}
\end{block}
\end{column}
\end{columns}




\end{frame}


\end{document}
